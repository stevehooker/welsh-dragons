{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stevehooker/welsh-dragons/blob/main/notebooks/comfyui_colab_optimised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ComfyUI on Google Colab\n",
        "\n",
        "**Version 2.2 - 31 Dec 2025**\n",
        "\n",
        "**Realistic expectations:**\n",
        "- Startup: ~30 minutes (Google Drive I/O is slow)\n",
        "- URL ready: ~10 minutes after startup completes\n",
        "- Model loading: Additional time depending on model size\n",
        "\n",
        "This is the nature of running from Google Drive. The T4 GPU is worth the wait if you need VRAM your local machine doesn't have.\n",
        "\n",
        "**Setup:**\n",
        "1. Runtime \u2192 Change runtime type \u2192 T4 GPU\n",
        "2. Runtime \u2192 Run all\n",
        "3. Wait for the cloudflared URL at the bottom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-secrets",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 0. Load Secrets (Optional)\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    secrets_found = []\n",
        "    for key in ['ANTHROPIC_API_KEY', 'OPENAI_API_KEY', 'HF_TOKEN']:\n",
        "        try:\n",
        "            value = userdata.get(key)\n",
        "            if value:\n",
        "                os.environ[key] = value\n",
        "                secrets_found.append(key)\n",
        "        except:\n",
        "            pass\n",
        "    if secrets_found:\n",
        "        print(f\"\u2713 Loaded: {', '.join(secrets_found)}\")\n",
        "    else:\n",
        "        print(\"\u2139\ufe0f  No secrets found\")\n",
        "except:\n",
        "    print(\"\u2139\ufe0f  Secrets not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount-drive",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "\n",
        "import os\n",
        "if not os.path.exists(WORKSPACE):\n",
        "    raise RuntimeError(f\"\u274c ComfyUI not found at {WORKSPACE}\")\n",
        "\n",
        "print(f\"\u2713 Workspace: {WORKSPACE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install-deps",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 2. Install Dependencies\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "%cd {WORKSPACE}\n",
        "\n",
        "print(\"Installing core requirements...\")\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q --upgrade comfyui-frontend-package\n",
        "\n",
        "print(\"\\nInstalling custom node dependencies (this takes a while)...\")\n",
        "!python custom_nodes/ComfyUI-Manager/cm-cli.py restore-dependencies\n",
        "\n",
        "print(f\"\\n\u2713 Done in {(time.time()-start)/60:.1f} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verify-gpu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3. Verify GPU\n",
        "import torch\n",
        "print(f\"PyTorch {torch.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "    print(\"\u2713 GPU ready\")\n",
        "else:\n",
        "    print(\"\u274c No GPU! Runtime \u2192 Change runtime type \u2192 T4 GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-comfyui"
      },
      "outputs": [],
      "source": [
        "#@title 4. Start ComfyUI\n",
        "import subprocess, threading, time, socket, re\n",
        "\n",
        "# Install cloudflared\n",
        "![ ! -f ~/cloudflared.deb ] && wget -q -O ~/cloudflared.deb https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i ~/cloudflared.deb 2>/dev/null\n",
        "\n",
        "url = None\n",
        "start_time = time.time()\n",
        "\n",
        "def tunnel(port=8188):\n",
        "    global url\n",
        "    # Wait for server\n",
        "    for _ in range(300):\n",
        "        try:\n",
        "            s = socket.socket()\n",
        "            s.settimeout(1)\n",
        "            if s.connect_ex(('127.0.0.1', port)) == 0:\n",
        "                s.close()\n",
        "                break\n",
        "        except:\n",
        "            pass\n",
        "        time.sleep(1)\n",
        "    \n",
        "    p = subprocess.Popen(['cloudflared', 'tunnel', '--url', f'http://127.0.0.1:{port}'],\n",
        "                         stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "    for line in p.stderr:\n",
        "        if 'trycloudflare.com' in line:\n",
        "            m = re.search(r'https://[a-z0-9-]+\\.trycloudflare\\.com', line)\n",
        "            if m:\n",
        "                url = m.group(0)\n",
        "                break\n",
        "\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd {WORKSPACE}\n",
        "print(\"Starting ComfyUI...\")\n",
        "print(\"Custom nodes will take several minutes to load from Drive.\\n\")\n",
        "\n",
        "p = subprocess.Popen(['python', 'main.py', '--dont-print-server'],\n",
        "                     stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
        "\n",
        "ready = False\n",
        "for line in p.stdout:\n",
        "    print(line, end='')\n",
        "    \n",
        "    if 'Import times for custom nodes:' in line and not ready:\n",
        "        ready = True\n",
        "        time.sleep(3)\n",
        "        elapsed = (time.time() - start_time) / 60\n",
        "        \n",
        "        # Wait for URL\n",
        "        for _ in range(30):\n",
        "            if url:\n",
        "                print(f\"\\n{'='*60}\")\n",
        "                print(f\"\ud83c\udf89 READY after {elapsed:.1f} minutes\")\n",
        "                print(f\"\ud83c\udf10 {url}\")\n",
        "                print(f\"{'='*60}\\n\")\n",
        "                break\n",
        "            time.sleep(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "notes"
      },
      "source": [
        "## Why is it slow?\n",
        "\n",
        "Google Drive is mounted via FUSE, which has ~100-500ms latency per file operation. Your `custom_nodes` folder has 18,841 files. Every Python import, every file read, every dependency check hits this latency.\n",
        "\n",
        "**There's no fix for this** \u2014 it's fundamental to how Colab + Drive works.\n",
        "\n",
        "## When is Colab worth it?\n",
        "\n",
        "When you need more VRAM than your local GPU has:\n",
        "- T4: 16 GB VRAM\n",
        "- A100: 40 or 80 GB VRAM\n",
        "- L4: 24 GB VRAM\n",
        "\n",
        "For 65 GB Flux Dev at 4 megapixel, you'll need A100 80GB."
      ]
    }
  ]
}